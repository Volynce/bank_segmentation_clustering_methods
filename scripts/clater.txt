import matplotlib.pyplot as plt
from sklearn.cluster import MiniBatchKMeans
from scipy.spatial.distance import euclidean
from sklearn import metrics
from sklearn.cluster import KMeans, AgglomerativeClustering, AffinityPropagation, SpectralClustering
import numpy as np
import pandas as pd
import os
from sklearn.cluster import KMeans
import matplotlib.pyplot as plt

df = pd.read_csv('/content/sample_data/DATASET FOR CASE.csv', sep='\t', encoding='cp1252', decimal=',')
df.dropna(inplace=True)
df = df.drop(df[df['Age of client'] < 18].index)
df = df.sample(n=10000, random_state=1) # Выбор случайных 10000 строк, для освобождения оперативной памяти при выполнении кластеризации

df = pd.read_csv('/content/sample_data/DATASET FOR CASE.csv', sep='\t', encoding='cp1252', decimal=',')
df.dropna(inplace=True)
df = df.drop(df[df['Age of client'] < 18].index)
df = df.sample(n=10000, random_state=1) # Выбор случайных 10000 строк, для освобождения оперативной памяти при выполнении кластеризации

df

# Удаление целевой переменной для кластеризации
df_dr = df.drop(columns=['TARGET (take a credit)'])

df_dr

# Метод локтя
inertia = []
k_range = range(1, 15)
for k in k_range:
    kmeans = KMeans(n_clusters=k, random_state=42)
    kmeans.fit(df_dr)
    inertia.append(kmeans.inertia_)

# Построение графика метода локтя
plt.figure(figsize=(15, 10))
plt.plot(k_range, inertia, marker='o')
plt.xlabel('Количество кластеров')
plt.ylabel('Inertia')
plt.title('Метод локтя для определения количества кластеров')
plt.show()

df1 = df_dr.copy()

kmeans = KMeans(n_clusters=3, n_init=20, init='k-means++', random_state=11)
kmeans.fit_predict(df1)

df1['Cluster'] = kmeans.labels_

df1['Cluster'].value_counts()

df1.groupby('Cluster').mean()

2. Агломеративная кластеризация

agg_cluster = AgglomerativeClustering(n_clusters=3, linkage='ward')

agg_cluster.fit_predict(df_dr)

df2 = df_dr.copy()

df2['Cluster'] = agg_cluster.labels_

df2.value_counts('Cluster')

df2.groupby('Cluster').mean()

3. Аффинная кластеризация (AffinityPropagation)

aff_cluster = AffinityPropagation()

aff_cluster.fit_predict(df_dr)

df3 = df_dr.copy()

df3['Cluster'] = aff_cluster.labels_

df3.value_counts('Cluster')

4. Спектральная кластеризация (SpectralClustering)

sp_cluster = SpectralClustering(n_clusters=3, affinity='nearest_neighbors')

sp_labels = sp_cluster.fit_predict(df_dr)

df4 = df_dr.copy()

df4['Cluster'] = sp_cluster.labels_

df4.value_counts('Cluster')

df4.groupby('Cluster').mean()

Оценка качества кластеризации с использованием метрик

from sklearn import metrics

X, y = df_dr, df['TARGET (take a credit)']

algorithms = []
algorithms.append(KMeans(n_clusters=3, n_init=20, init='k-means++', random_state=11))
algorithms.append(AffinityPropagation())
algorithms.append(SpectralClustering(n_clusters=3, random_state=12, affinity='nearest_neighbors'))
algorithms.append(AgglomerativeClustering(n_clusters=4, linkage='ward'))


data = []
for algo in algorithms:
    algo.fit(X)
    data.append(({
        'ARI': metrics.adjusted_rand_score(y, algo.labels_),
        'AMI': metrics.adjusted_mutual_info_score(y, algo.labels_),
        'Homogenity': metrics.homogeneity_score(y, algo.labels_),
        'Completeness': metrics.completeness_score(y, algo.labels_),
        'V-measure': metrics.v_measure_score(y, algo.labels_),
        'Silhouette': metrics.silhouette_score(X, algo.labels_)}))

results = pd.DataFrame(data=data, columns=['ARI', 'AMI', 'Homogenity',
                                           'Completeness', 'V-measure',
                                           'Silhouette'],
                       index=['K-means', 'Affinity',
                              'Spectral', 'Agglomerative'])

results



*   K-means демонстрирует лучшее качество кластеризации, особенно по метрике Silhouette Score, что свидетельствует о хорошей разделимости кластеров. Однако, несмотря на это, его метрики качества кластеризации в контексте целевой переменной остаются слабыми, что подтверждается отрицательными значениями ARI и AMI.

*   Affinity Propagation демонстрирует более высокие значения в метриках гомогенности, полноты и V-measure, но эти значения по-прежнему очень низкие. Сила этого алгоритма заключается в том, что он не требует предварительного указания количества кластеров, однако, его качество кластеризации тоже оставляет желать лучшего.

*   Spectral Clustering и Agglomerative Clustering показывают схожие результаты, их показатели качества кластеризации тоже достаточно низкие. При этом, их силуэтный показатель ниже, чем у K-means, что указывает на более слабую разделимость кластеров.